{"cells":[{"cell_type":"markdown","metadata":{"id":"NLSBoGtbwVqY"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8LlP3G3ws-zl"},"outputs":[],"source":["import os\n","import shutil\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"QC28pFoWw2wD"},"source":["# Preparing the Data Folders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_9TsWzt2Ha7"},"outputs":[],"source":["model_ckpt = '/content/drive/MyDrive/VAE/BAYC/Models/'\n","train_path = '/content/drive/MyDrive/VAE/BAYC/Train_data/'\n","test_path = '/content/drive/MyDrive/VAE/BAYC/Test_data/'"]},{"cell_type":"markdown","metadata":{"id":"DTN8GW8Dwpa7"},"source":["# Encoder and Decoder Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyh_ETgZwU1t"},"outputs":[],"source":["latent_dim = 16\n","image_size = 512\n","\n","# Encoder\n","encoder = tf.keras.Sequential(\n","    [\n","        tf.keras.layers.InputLayer(input_shape=(image_size, image_size, 3)),\n","        tf.keras.layers.Conv2D(\n","            filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n","        tf.keras.layers.Conv2D(\n","            filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(latent_dim + latent_dim, kernel_initializer=\"zeros\"),\n","    ]\n",")\n","\n","# Decoder\n","latent_inputs = keras.Input(shape=(latent_dim,))\n","x = layers.Dense(image_size//4 * image_size//4 * 64, activation=\"relu\")(latent_inputs)\n","x = layers.Reshape((image_size//4, image_size//4, 64))(x)\n","x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n","decoder = keras.Model(latent_inputs, decoder_outputs)"]},{"cell_type":"markdown","metadata":{"id":"_gDvG7wHwtUT"},"source":["# VAE Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9x4YUxwv3hX"},"outputs":[],"source":["class VAE(tf.keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def encode(self, x):\n","        mean_logvar = self.encoder(x)\n","        mean, logvar = tf.split(mean_logvar, num_or_size_splits=2, axis=1)\n","        return mean, logvar\n","\n","    def reparameterize(self, mean, logvar):\n","        eps = tf.random.normal(shape=mean.shape)\n","        return eps * tf.exp(logvar * 0.5) + mean\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def call(self, x):\n","        mean, logvar = self.encode(x)\n","        z = self.reparameterize(mean, logvar)\n","        return self.decode(z)\n","\n","vae = VAE(encoder, decoder)\n","\n","optimizer = tf.keras.optimizers.Adam(1e-5)\n","\n","def log_normal_pdf(sample, mean, logvar, raxis=1):\n","    log2pi = tf.math.log(2. * np.pi)\n","    epsilon = 1e-8\n","    return tf.reduce_sum(\n","        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar + epsilon) + logvar + log2pi),\n","        axis=raxis)\n","\n","\n","def compute_loss(model, x):\n","    mean, logvar = model.encode(x)\n","    z = model.reparameterize(mean, logvar)\n","    x_logit = model.decode(z)\n","    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n","    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n","    logpz = log_normal_pdf(z, 0., 0.)\n","    logqz_x = log_normal_pdf(z, mean, logvar)\n","    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n","\n","@tf.function\n","def train_step(model, x, optimizer):\n","    with tf.GradientTape() as tape:\n","        loss = compute_loss(model, x)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    clipped_gradients = [tf.clip_by_value(grad, -1.0, 1.0) for grad in gradients]\n","    optimizer.apply_gradients(zip(clipped_gradients, model.trainable_variables))"]},{"cell_type":"markdown","metadata":{"id":"xgzCFZxHwziu"},"source":["# Data Loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLnTa9lCv4QX","executionInfo":{"status":"ok","timestamp":1683669009915,"user_tz":-180,"elapsed":68394,"user":{"displayName":"Danu intern","userId":"14685699878604878640"}},"outputId":"8aa5c9a2-fc2c-4a67-99b7-2b97d3c3c98c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7914 files belonging to 1 classes.\n","Found 1988 files belonging to 1 classes.\n"]}],"source":["train_ds = tf.keras.utils.image_dataset_from_directory(\n","    directory=train_path,\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=80,\n","    image_size=(image_size, image_size))\n","\n","valid_ds = tf.keras.utils.image_dataset_from_directory(\n","    directory=test_path,\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=80,\n","    image_size=(image_size, image_size))\n","\n","normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n","\n","train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))#.cache()\n","valid_ds = valid_ds.map(lambda x, y: (normalization_layer(x), y))#.cache()"]},{"cell_type":"markdown","metadata":{"id":"7fqAyFGlw9zu"},"source":["# Training Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OKIFg_ipkxs"},"outputs":[],"source":["ckpt = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder, step=tf.Variable(0))\n","manager = tf.train.CheckpointManager(ckpt, model_ckpt, max_to_keep=1)"]},{"cell_type":"code","source":["if manager.latest_checkpoint:\n","    print(\"Restored from {}\".format(manager.latest_checkpoint))\n","    ckpt.restore(manager.latest_checkpoint)\n","else:\n","    print(\"Initializing from scratch.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"MjQNq1sFNwse","executionInfo":{"status":"error","timestamp":1683669010334,"user_tz":-180,"elapsed":429,"user":{"displayName":"Danu intern","userId":"14685699878604878640"}},"outputId":"b90bd16c-3fba-44a7-a4d4-bc3b0b37f657"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Restored from /content/drive/MyDrive/VAE/BAYC/Models/ckpt-10\n"]},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /content/drive/MyDrive/VAE/BAYC/Models/ckpt-10","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2592\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2462\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2463\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2464\u001b[0m     metrics.AddCheckpointReadDuration(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m     \u001b[0mgraph_building\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     30\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n","\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /content/drive/MyDrive/VAE/BAYC/Models/ckpt-10","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-edeb95322a5f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restored from {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing from scratch.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2593\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure restore operations have completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2595\u001b[0;31m       raise errors_impl.NotFoundError(\n\u001b[0m\u001b[1;32m   2596\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m           \u001b[0;34mf\"Error when restoring from checkpoint or SavedModel at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Error when restoring from checkpoint or SavedModel at /content/drive/MyDrive/VAE/BAYC/Models/ckpt-10: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /content/drive/MyDrive/VAE/BAYC/Models/ckpt-10\nPlease double-check that the path is correct. You may be missing the checkpoint suffix (e.g. the '-1' in 'path/to/ckpt-1')."]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igYZEtqev7AR"},"outputs":[],"source":["epochs = 50\n","\n","for epoch in range(epochs):\n","    for train_x, _ in train_ds:\n","        train_step(vae, train_x, optimizer)\n","        ckpt.step.assign_add(1)\n","        if int(ckpt.step) % 200 == 0:\n","            save_path = manager.save()\n","            print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n","\n","    train_loss = tf.keras.metrics.Mean()\n","    valid_loss = tf.keras.metrics.Mean()\n","\n","    for train_x, _ in train_ds:\n","        train_loss(compute_loss(vae, train_x))\n","    for valid_x, _ in valid_ds:\n","        valid_loss(compute_loss(vae, valid_x))\n","    print(f\"Epoch {epoch + 1}, Train loss: {train_loss.result()}, Validation loss: {valid_loss.result()}\")"]},{"cell_type":"markdown","metadata":{"id":"fO2Tm0Tdw_s6"},"source":["# Testing and Validation Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvShagEfqS7W"},"outputs":[],"source":["test_batch = next(iter(valid_ds))\n","test_image = test_batch[0][0:1]\n","\n","plt.figure()\n","plt.imshow(test_image[0])\n","plt.title(\"Original Image\")\n","plt.show()\n","\n","mean_logvar = encoder(test_image)\n","mean, logvar = tf.split(mean_logvar, num_or_size_splits=2, axis=1)\n","z = vae.reparameterize(mean, logvar)\n","decoded_image = decoder(z)\n","\n","plt.figure()\n","plt.imshow(decoded_image[0])\n","plt.title(\"Decoder Output\")\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","mount_file_id":"1eQ3igpF8JxKyznqxVTjU91ctbJ68kh4Z","authorship_tag":"ABX9TyMo1Jka4UpJaWC9xBElaRJS"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}